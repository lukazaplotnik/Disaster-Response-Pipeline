{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zaplu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zaplu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zaplu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet','stopwords'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report, make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///disaster_response.db')\n",
    "df = pd.read_sql_table('messages', engine)\n",
    "\n",
    "# Define feature and target variables X and Y\n",
    "X = df['message']\n",
    "Y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26180,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26180, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'water', 'food', 'shelter', 'clothing', 'money', 'missing_people',\n",
       "       'refugees', 'death', 'other_aid', 'infrastructure_related',\n",
       "       'transport', 'buildings', 'electricity', 'tools', 'hospitals',\n",
       "       'shops', 'aid_centers', 'other_infrastructure', 'weather_related',\n",
       "       'floods', 'storm', 'fire', 'earthquake', 'cold', 'other_weather',\n",
       "       'direct_report'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    #Transform the text to lowercase plus remove all characters that are not letters or numbers\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text.lower())\n",
    "    \n",
    "    #Tokenize the text to words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    #Remove stopwords and whitespace around the words\n",
    "    tokens_subset = [v.strip() for v in tokens if v.strip() not in set(stopwords.words('english'))]\n",
    "    \n",
    "    #Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmed = [lemmatizer.lemmatize(w) for w in tokens_subset]\n",
    "    \n",
    "    return lemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nothing', 'eat', 'water', 'starving', 'thirsty']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(X[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the feature variable - message lengths\n",
    "lengths= []\n",
    "for i in range(X.shape[0]):\n",
    "    lengths.append(len(X[i]))\n",
    "ls = pd.Series(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related 148.0 186.0\n",
      "request 185.0 150.0\n",
      "offer 179.0 200.5\n",
      "aid_related 163.0 197.0\n",
      "medical_help 174.0 219.0\n",
      "medical_products 176.0 221.0\n",
      "search_and_rescue 178.0 204.0\n",
      "security 178.0 207.5\n",
      "military 176.0 237.0\n",
      "water 177.0 203.0\n",
      "food 178.0 184.0\n",
      "shelter 176.0 202.0\n",
      "clothing 178.0 210.0\n",
      "money 177.0 229.5\n",
      "missing_people 178.0 199.0\n",
      "refugees 176.0 229.5\n",
      "death 176.0 216.25\n",
      "other_aid 176.0 191.0\n",
      "infrastructure_related 175.0 222.0\n",
      "transport 176.0 214.0\n",
      "buildings 177.0 211.0\n",
      "electricity 178.0 215.5\n",
      "tools 178.0 243.0\n",
      "hospitals 178.0 228.0\n",
      "shops 178.0 227.0\n",
      "aid_centers 178.0 221.0\n",
      "other_infrastructure 176.0 223.0\n",
      "weather_related 169.0 201.0\n",
      "floods 173.0 224.0\n",
      "storm 174.0 212.25\n",
      "fire 178.0 217.75\n",
      "earthquake 179.0 171.0\n",
      "cold 178.0 215.0\n",
      "other_weather 176.0 218.0\n",
      "direct_report 185.0 153.0\n"
     ]
    }
   ],
   "source": [
    "#Explore the feature variable - message lengths and corresponding quantiles\n",
    "for col in Y.columns:\n",
    "    print(col, ls[df[col]==0].quantile(0.75),ls[df[col]==1].quantile(0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a machine learning pipeline \n",
    "pipeline = Pipeline([\n",
    "    ('count', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))   \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25)\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(pipeline.predict(X_test), columns = y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6081393282388483"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combined f1_score\n",
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.48      0.54      1487\n",
      "           1       0.86      0.91      0.88      5058\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      6545\n",
      "   macro avg       0.73      0.70      0.71      6545\n",
      "weighted avg       0.80      0.81      0.80      6545\n",
      "\n",
      "request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      5454\n",
      "           1       0.77      0.45      0.57      1091\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      6545\n",
      "   macro avg       0.83      0.71      0.75      6545\n",
      "weighted avg       0.88      0.89      0.87      6545\n",
      "\n",
      "offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6515\n",
      "           1       0.00      0.00      0.00        30\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.50      0.50      0.50      6545\n",
      "weighted avg       0.99      0.99      0.99      6545\n",
      "\n",
      "aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80      3823\n",
      "           1       0.75      0.59      0.66      2722\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      6545\n",
      "   macro avg       0.75      0.73      0.73      6545\n",
      "weighted avg       0.75      0.75      0.74      6545\n",
      "\n",
      "medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      6043\n",
      "           1       0.69      0.11      0.19       502\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      6545\n",
      "   macro avg       0.81      0.55      0.58      6545\n",
      "weighted avg       0.91      0.93      0.90      6545\n",
      "\n",
      "medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6219\n",
      "           1       0.80      0.12      0.21       326\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      6545\n",
      "   macro avg       0.88      0.56      0.59      6545\n",
      "weighted avg       0.95      0.95      0.94      6545\n",
      "\n",
      "search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6367\n",
      "           1       0.68      0.08      0.15       178\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      6545\n",
      "   macro avg       0.83      0.54      0.57      6545\n",
      "weighted avg       0.97      0.97      0.96      6545\n",
      "\n",
      "security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6414\n",
      "           1       0.00      0.00      0.00       131\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      6545\n",
      "   macro avg       0.49      0.50      0.49      6545\n",
      "weighted avg       0.96      0.98      0.97      6545\n",
      "\n",
      "military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6314\n",
      "           1       0.64      0.08      0.14       231\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      6545\n",
      "   macro avg       0.81      0.54      0.56      6545\n",
      "weighted avg       0.96      0.97      0.95      6545\n",
      "\n",
      "water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6139\n",
      "           1       0.85      0.30      0.44       406\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      6545\n",
      "   macro avg       0.90      0.65      0.71      6545\n",
      "weighted avg       0.95      0.95      0.94      6545\n",
      "\n",
      "food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      5815\n",
      "           1       0.85      0.44      0.58       730\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      6545\n",
      "   macro avg       0.89      0.72      0.77      6545\n",
      "weighted avg       0.92      0.93      0.92      6545\n",
      "\n",
      "shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      5969\n",
      "           1       0.84      0.34      0.48       576\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      6545\n",
      "   macro avg       0.89      0.66      0.72      6545\n",
      "weighted avg       0.93      0.94      0.92      6545\n",
      "\n",
      "clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6441\n",
      "           1       0.73      0.11      0.18       104\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.86      0.55      0.59      6545\n",
      "weighted avg       0.98      0.99      0.98      6545\n",
      "\n",
      "money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6395\n",
      "           1       1.00      0.04      0.08       150\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      6545\n",
      "   macro avg       0.99      0.52      0.53      6545\n",
      "weighted avg       0.98      0.98      0.97      6545\n",
      "\n",
      "missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6469\n",
      "           1       1.00      0.03      0.05        76\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.99      0.51      0.52      6545\n",
      "weighted avg       0.99      0.99      0.98      6545\n",
      "\n",
      "refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6326\n",
      "           1       0.62      0.07      0.12       219\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      6545\n",
      "   macro avg       0.80      0.53      0.55      6545\n",
      "weighted avg       0.96      0.97      0.95      6545\n",
      "\n",
      "death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6213\n",
      "           1       0.80      0.13      0.22       332\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      6545\n",
      "   macro avg       0.88      0.56      0.60      6545\n",
      "weighted avg       0.95      0.95      0.94      6545\n",
      "\n",
      "other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      5687\n",
      "           1       0.55      0.05      0.10       858\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      6545\n",
      "   macro avg       0.71      0.52      0.51      6545\n",
      "weighted avg       0.83      0.87      0.82      6545\n",
      "\n",
      "infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      6108\n",
      "           1       0.22      0.00      0.01       437\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      6545\n",
      "   macro avg       0.58      0.50      0.49      6545\n",
      "weighted avg       0.89      0.93      0.90      6545\n",
      "\n",
      "transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6279\n",
      "           1       0.54      0.08      0.13       266\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      6545\n",
      "   macro avg       0.75      0.54      0.56      6545\n",
      "weighted avg       0.95      0.96      0.94      6545\n",
      "\n",
      "buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6209\n",
      "           1       0.66      0.09      0.16       336\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      6545\n",
      "   macro avg       0.81      0.54      0.57      6545\n",
      "weighted avg       0.94      0.95      0.93      6545\n",
      "\n",
      "electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6398\n",
      "           1       1.00      0.04      0.08       147\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      6545\n",
      "   macro avg       0.99      0.52      0.53      6545\n",
      "weighted avg       0.98      0.98      0.97      6545\n",
      "\n",
      "tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6501\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.50      0.50      0.50      6545\n",
      "weighted avg       0.99      0.99      0.99      6545\n",
      "\n",
      "hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6475\n",
      "           1       0.00      0.00      0.00        70\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.49      0.50      0.50      6545\n",
      "weighted avg       0.98      0.99      0.98      6545\n",
      "\n",
      "shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6507\n",
      "           1       0.00      0.00      0.00        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.50      0.50      0.50      6545\n",
      "weighted avg       0.99      0.99      0.99      6545\n",
      "\n",
      "aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6468\n",
      "           1       0.00      0.00      0.00        77\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.49      0.50      0.50      6545\n",
      "weighted avg       0.98      0.99      0.98      6545\n",
      "\n",
      "other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6259\n",
      "           1       0.00      0.00      0.00       286\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      6545\n",
      "   macro avg       0.48      0.50      0.49      6545\n",
      "weighted avg       0.91      0.96      0.93      6545\n",
      "\n",
      "weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      4730\n",
      "           1       0.84      0.65      0.73      1815\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      6545\n",
      "   macro avg       0.86      0.80      0.82      6545\n",
      "weighted avg       0.87      0.87      0.86      6545\n",
      "\n",
      "floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      6002\n",
      "           1       0.86      0.39      0.53       543\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      6545\n",
      "   macro avg       0.90      0.69      0.75      6545\n",
      "weighted avg       0.94      0.94      0.93      6545\n",
      "\n",
      "storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      5940\n",
      "           1       0.73      0.43      0.54       605\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      6545\n",
      "   macro avg       0.84      0.71      0.75      6545\n",
      "weighted avg       0.92      0.93      0.92      6545\n",
      "\n",
      "fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6469\n",
      "           1       0.75      0.04      0.07        76\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.87      0.52      0.53      6545\n",
      "weighted avg       0.99      0.99      0.98      6545\n",
      "\n",
      "earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5930\n",
      "           1       0.90      0.73      0.81       615\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      6545\n",
      "   macro avg       0.94      0.86      0.90      6545\n",
      "weighted avg       0.97      0.97      0.97      6545\n",
      "\n",
      "cold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6418\n",
      "           1       0.75      0.12      0.20       127\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      6545\n",
      "   macro avg       0.87      0.56      0.60      6545\n",
      "weighted avg       0.98      0.98      0.98      6545\n",
      "\n",
      "other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6196\n",
      "           1       0.50      0.06      0.11       349\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      6545\n",
      "   macro avg       0.72      0.53      0.54      6545\n",
      "weighted avg       0.93      0.95      0.93      6545\n",
      "\n",
      "direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      5315\n",
      "           1       0.72      0.32      0.44      1230\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      6545\n",
      "   macro avg       0.79      0.64      0.68      6545\n",
      "weighted avg       0.83      0.85      0.82      6545\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaplu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Binary classification metrics per output category\n",
    "for col in y_test.columns:\n",
    "    print(col)\n",
    "    print(classification_report(y_test[col],y_pred[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('count',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x000001D74972D0D0>,\n",
       "           vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "               max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "               oob_score=False, random_state=None, verbose=0,\n",
       "               warm_start=False),\n",
       "              n_jobs=None))],\n",
       " 'count': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x000001D74972D0D0>,\n",
       "         vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       "            n_jobs=None),\n",
       " 'count__analyzer': 'word',\n",
       " 'count__binary': False,\n",
       " 'count__decode_error': 'strict',\n",
       " 'count__dtype': numpy.int64,\n",
       " 'count__encoding': 'utf-8',\n",
       " 'count__input': 'content',\n",
       " 'count__lowercase': True,\n",
       " 'count__max_df': 1.0,\n",
       " 'count__max_features': None,\n",
       " 'count__min_df': 1,\n",
       " 'count__ngram_range': (1, 1),\n",
       " 'count__preprocessor': None,\n",
       " 'count__stop_words': None,\n",
       " 'count__strip_accents': None,\n",
       " 'count__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'count__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'count__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 'warn',\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters of the model\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaplu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed: 49.0min\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed: 446.3min\n",
      "[Parallel(n_jobs=6)]: Done 144 out of 144 | elapsed: 518.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('count', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        stri..._score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=6,\n",
       "       param_grid={'count__max_df': [0.75, 1.0], 'count__ngram_range': [(1, 1), (1, 2)], 'tfidf__smooth_idf': [True, False], 'clf__estimator__min_samples_split': [2, 10, 50], 'clf__estimator__n_estimators': [10, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(f1_score, average=micro), verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search\n",
    "parameters = {'count__max_df': [0.75, 1.0], #0.75\n",
    "              'count__ngram_range': [(1,1),(1,2)], #(1,1)\n",
    "              #'count__max_features' : [100,200],\n",
    "              'tfidf__smooth_idf':[True, False], #True\n",
    "              #'clf__estimator__max_depth': [None,4,8],\n",
    "              'clf__estimator__min_samples_split': [2, 10, 50], #10\n",
    "              'clf__estimator__n_estimators': [10, 50] #50\n",
    "             }\n",
    "\n",
    "#Instead of averaging the f1 score achieved on different categories,\n",
    "#we perform the grid search with respect to the global f1_score that counts the total true positives, false negatives and false positives.\n",
    "#this is achieved by defining a custom scorer and setting the average parameter to average='micro'.\n",
    "#In turn more emphasis is put on the categories with more positive labels in the testing set.\n",
    "#Overall we do not believe this poses a major concern, since we ultimately care about the total performance,\n",
    "#rather than achieving a high score in each of the categories. Specific categories are often highly unbalanced and have very little positive labels,\n",
    "#therefore, we do not want that a poor performance on one such category offsets a good performance on a more material/important category.\n",
    "\n",
    "total_scorer = make_scorer(f1_score, average = 'micro')\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters, scoring = total_scorer, verbose = 3, n_jobs = 6)\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaplu\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\zaplu\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\zaplu\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\zaplu\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\zaplu\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__estimator__min_samples_split</th>\n",
       "      <th>param_clf__estimator__n_estimators</th>\n",
       "      <th>param_count__max_df</th>\n",
       "      <th>param_count__ngram_range</th>\n",
       "      <th>param_tfidf__smooth_idf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.790186</td>\n",
       "      <td>132.170944</td>\n",
       "      <td>9.292411</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.646104</td>\n",
       "      <td>0.647428</td>\n",
       "      <td>0.643834</td>\n",
       "      <td>0.645789</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946455</td>\n",
       "      <td>0.945730</td>\n",
       "      <td>0.946411</td>\n",
       "      <td>0.946199</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>130.070811</td>\n",
       "      <td>140.338393</td>\n",
       "      <td>29.341547</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.645896</td>\n",
       "      <td>0.643297</td>\n",
       "      <td>0.644738</td>\n",
       "      <td>0.644644</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>2</td>\n",
       "      <td>0.945473</td>\n",
       "      <td>0.946781</td>\n",
       "      <td>0.947829</td>\n",
       "      <td>0.946694</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>25.810716</td>\n",
       "      <td>173.954488</td>\n",
       "      <td>10.838890</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.642513</td>\n",
       "      <td>0.644622</td>\n",
       "      <td>0.645628</td>\n",
       "      <td>0.644255</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>3</td>\n",
       "      <td>0.946024</td>\n",
       "      <td>0.945802</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.946398</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8.702223</td>\n",
       "      <td>114.033495</td>\n",
       "      <td>5.106103</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.644768</td>\n",
       "      <td>0.644787</td>\n",
       "      <td>0.642521</td>\n",
       "      <td>0.644025</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>4</td>\n",
       "      <td>0.946370</td>\n",
       "      <td>0.946305</td>\n",
       "      <td>0.948117</td>\n",
       "      <td>0.946931</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>59.576437</td>\n",
       "      <td>157.021001</td>\n",
       "      <td>20.917853</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.646768</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.641883</td>\n",
       "      <td>0.642050</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>5</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.881446</td>\n",
       "      <td>0.882753</td>\n",
       "      <td>0.882305</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>31.162243</td>\n",
       "      <td>113.612712</td>\n",
       "      <td>2.081775</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.643180</td>\n",
       "      <td>0.640166</td>\n",
       "      <td>0.641122</td>\n",
       "      <td>0.641489</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>6</td>\n",
       "      <td>0.882125</td>\n",
       "      <td>0.881156</td>\n",
       "      <td>0.879875</td>\n",
       "      <td>0.881052</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.189027</td>\n",
       "      <td>117.861618</td>\n",
       "      <td>2.680167</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.643297</td>\n",
       "      <td>0.639647</td>\n",
       "      <td>0.641343</td>\n",
       "      <td>0.641429</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>7</td>\n",
       "      <td>0.881258</td>\n",
       "      <td>0.880984</td>\n",
       "      <td>0.881090</td>\n",
       "      <td>0.881111</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>7.213611</td>\n",
       "      <td>197.770372</td>\n",
       "      <td>10.708740</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.640349</td>\n",
       "      <td>0.640589</td>\n",
       "      <td>0.640200</td>\n",
       "      <td>0.640379</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>8</td>\n",
       "      <td>0.882277</td>\n",
       "      <td>0.881384</td>\n",
       "      <td>0.881425</td>\n",
       "      <td>0.881695</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.194074</td>\n",
       "      <td>104.414408</td>\n",
       "      <td>4.075895</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.635859</td>\n",
       "      <td>0.634178</td>\n",
       "      <td>0.635888</td>\n",
       "      <td>0.635308</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996328</td>\n",
       "      <td>0.996472</td>\n",
       "      <td>0.996516</td>\n",
       "      <td>0.996439</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.382524</td>\n",
       "      <td>239.590553</td>\n",
       "      <td>19.331161</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.638198</td>\n",
       "      <td>0.633463</td>\n",
       "      <td>0.633895</td>\n",
       "      <td>0.635185</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>10</td>\n",
       "      <td>0.996159</td>\n",
       "      <td>0.996726</td>\n",
       "      <td>0.996563</td>\n",
       "      <td>0.996483</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.392148</td>\n",
       "      <td>101.094927</td>\n",
       "      <td>5.576110</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.638495</td>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.630324</td>\n",
       "      <td>0.634845</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>11</td>\n",
       "      <td>0.917717</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916965</td>\n",
       "      <td>0.917394</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35.688345</td>\n",
       "      <td>143.502429</td>\n",
       "      <td>31.635779</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.638381</td>\n",
       "      <td>0.635354</td>\n",
       "      <td>0.630446</td>\n",
       "      <td>0.634727</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>12</td>\n",
       "      <td>0.996268</td>\n",
       "      <td>0.996641</td>\n",
       "      <td>0.996659</td>\n",
       "      <td>0.996523</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29.643903</td>\n",
       "      <td>148.753648</td>\n",
       "      <td>16.455862</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.632239</td>\n",
       "      <td>0.635894</td>\n",
       "      <td>0.631500</td>\n",
       "      <td>0.633211</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>13</td>\n",
       "      <td>0.918219</td>\n",
       "      <td>0.917419</td>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.918377</td>\n",
       "      <td>0.000854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.231480</td>\n",
       "      <td>94.932876</td>\n",
       "      <td>3.066692</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.632726</td>\n",
       "      <td>0.630385</td>\n",
       "      <td>0.634395</td>\n",
       "      <td>0.632502</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>14</td>\n",
       "      <td>0.996232</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.996898</td>\n",
       "      <td>0.996546</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.976929</td>\n",
       "      <td>118.644085</td>\n",
       "      <td>7.356616</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.637248</td>\n",
       "      <td>0.630135</td>\n",
       "      <td>0.629478</td>\n",
       "      <td>0.632287</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>15</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.917943</td>\n",
       "      <td>0.920436</td>\n",
       "      <td>0.918952</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20.522554</td>\n",
       "      <td>125.452465</td>\n",
       "      <td>5.259132</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.635059</td>\n",
       "      <td>0.628885</td>\n",
       "      <td>0.632209</td>\n",
       "      <td>0.632051</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>16</td>\n",
       "      <td>0.920448</td>\n",
       "      <td>0.917567</td>\n",
       "      <td>0.917750</td>\n",
       "      <td>0.918588</td>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11.847645</td>\n",
       "      <td>95.731016</td>\n",
       "      <td>4.661868</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.632163</td>\n",
       "      <td>0.627110</td>\n",
       "      <td>0.628243</td>\n",
       "      <td>0.629172</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>17</td>\n",
       "      <td>0.983988</td>\n",
       "      <td>0.983544</td>\n",
       "      <td>0.983948</td>\n",
       "      <td>0.983826</td>\n",
       "      <td>0.000201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.633655</td>\n",
       "      <td>95.248912</td>\n",
       "      <td>4.973207</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.636286</td>\n",
       "      <td>0.620743</td>\n",
       "      <td>0.630389</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>18</td>\n",
       "      <td>0.861440</td>\n",
       "      <td>0.856761</td>\n",
       "      <td>0.861151</td>\n",
       "      <td>0.859784</td>\n",
       "      <td>0.002141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.686717</td>\n",
       "      <td>154.615375</td>\n",
       "      <td>37.057258</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.630874</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.628411</td>\n",
       "      <td>0.629041</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>19</td>\n",
       "      <td>0.861287</td>\n",
       "      <td>0.860480</td>\n",
       "      <td>0.861266</td>\n",
       "      <td>0.861011</td>\n",
       "      <td>0.000376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10.278171</td>\n",
       "      <td>136.298787</td>\n",
       "      <td>41.011605</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.630736</td>\n",
       "      <td>0.626188</td>\n",
       "      <td>0.628994</td>\n",
       "      <td>0.628639</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>20</td>\n",
       "      <td>0.861648</td>\n",
       "      <td>0.859235</td>\n",
       "      <td>0.861125</td>\n",
       "      <td>0.860669</td>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>243.836172</td>\n",
       "      <td>112.245066</td>\n",
       "      <td>37.323402</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.630307</td>\n",
       "      <td>0.627702</td>\n",
       "      <td>0.627015</td>\n",
       "      <td>0.628341</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>21</td>\n",
       "      <td>0.983819</td>\n",
       "      <td>0.983864</td>\n",
       "      <td>0.984385</td>\n",
       "      <td>0.984023</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.496860</td>\n",
       "      <td>121.330342</td>\n",
       "      <td>16.520930</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.627853</td>\n",
       "      <td>0.625522</td>\n",
       "      <td>0.630695</td>\n",
       "      <td>0.628023</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>22</td>\n",
       "      <td>0.983645</td>\n",
       "      <td>0.983133</td>\n",
       "      <td>0.984522</td>\n",
       "      <td>0.983767</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10.555890</td>\n",
       "      <td>107.901394</td>\n",
       "      <td>5.918489</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.629049</td>\n",
       "      <td>0.625330</td>\n",
       "      <td>0.629054</td>\n",
       "      <td>0.627811</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>23</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.984448</td>\n",
       "      <td>0.984879</td>\n",
       "      <td>0.984428</td>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6.474830</td>\n",
       "      <td>176.256373</td>\n",
       "      <td>9.897513</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.630896</td>\n",
       "      <td>0.625096</td>\n",
       "      <td>0.625681</td>\n",
       "      <td>0.627224</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>24</td>\n",
       "      <td>0.958362</td>\n",
       "      <td>0.959242</td>\n",
       "      <td>0.959646</td>\n",
       "      <td>0.959083</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>25.587177</td>\n",
       "      <td>158.948393</td>\n",
       "      <td>5.960802</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.627693</td>\n",
       "      <td>0.625834</td>\n",
       "      <td>0.626459</td>\n",
       "      <td>0.626662</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>25</td>\n",
       "      <td>0.958476</td>\n",
       "      <td>0.958593</td>\n",
       "      <td>0.959416</td>\n",
       "      <td>0.958828</td>\n",
       "      <td>0.000419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>83.237135</td>\n",
       "      <td>136.415379</td>\n",
       "      <td>6.667605</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.628462</td>\n",
       "      <td>0.621072</td>\n",
       "      <td>0.630242</td>\n",
       "      <td>0.626592</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>26</td>\n",
       "      <td>0.959467</td>\n",
       "      <td>0.959639</td>\n",
       "      <td>0.958888</td>\n",
       "      <td>0.959332</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>21.480496</td>\n",
       "      <td>98.040819</td>\n",
       "      <td>6.773904</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.628096</td>\n",
       "      <td>0.631468</td>\n",
       "      <td>0.619927</td>\n",
       "      <td>0.626497</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>27</td>\n",
       "      <td>0.860684</td>\n",
       "      <td>0.859526</td>\n",
       "      <td>0.861376</td>\n",
       "      <td>0.860529</td>\n",
       "      <td>0.000764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11.489862</td>\n",
       "      <td>135.875515</td>\n",
       "      <td>6.563294</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.625823</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.626056</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>28</td>\n",
       "      <td>0.960199</td>\n",
       "      <td>0.959668</td>\n",
       "      <td>0.959691</td>\n",
       "      <td>0.959853</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.359034</td>\n",
       "      <td>115.031386</td>\n",
       "      <td>1.574578</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.621524</td>\n",
       "      <td>0.616814</td>\n",
       "      <td>0.615634</td>\n",
       "      <td>0.617991</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>29</td>\n",
       "      <td>0.940395</td>\n",
       "      <td>0.940469</td>\n",
       "      <td>0.942103</td>\n",
       "      <td>0.940989</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9.855070</td>\n",
       "      <td>100.816350</td>\n",
       "      <td>6.718141</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.618984</td>\n",
       "      <td>0.615040</td>\n",
       "      <td>0.614089</td>\n",
       "      <td>0.616038</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>30</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.911611</td>\n",
       "      <td>0.913086</td>\n",
       "      <td>0.913072</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9.150624</td>\n",
       "      <td>120.634084</td>\n",
       "      <td>11.757095</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.618960</td>\n",
       "      <td>0.613228</td>\n",
       "      <td>0.614733</td>\n",
       "      <td>0.615640</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>31</td>\n",
       "      <td>0.915178</td>\n",
       "      <td>0.913201</td>\n",
       "      <td>0.914271</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.000808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.842788</td>\n",
       "      <td>145.322078</td>\n",
       "      <td>2.789279</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.620537</td>\n",
       "      <td>0.610478</td>\n",
       "      <td>0.614214</td>\n",
       "      <td>0.615076</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>32</td>\n",
       "      <td>0.995592</td>\n",
       "      <td>0.995976</td>\n",
       "      <td>0.995904</td>\n",
       "      <td>0.995824</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>46.185659</td>\n",
       "      <td>111.222490</td>\n",
       "      <td>7.334794</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.621379</td>\n",
       "      <td>0.606895</td>\n",
       "      <td>0.614145</td>\n",
       "      <td>0.614140</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>33</td>\n",
       "      <td>0.941143</td>\n",
       "      <td>0.941952</td>\n",
       "      <td>0.942418</td>\n",
       "      <td>0.941837</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18.172808</td>\n",
       "      <td>124.182717</td>\n",
       "      <td>7.795156</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.611466</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.614017</td>\n",
       "      <td>0.614102</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>34</td>\n",
       "      <td>0.942164</td>\n",
       "      <td>0.942414</td>\n",
       "      <td>0.943222</td>\n",
       "      <td>0.942600</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44.642881</td>\n",
       "      <td>174.993811</td>\n",
       "      <td>24.013595</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 10, 'clf...</td>\n",
       "      <td>0.617511</td>\n",
       "      <td>0.606352</td>\n",
       "      <td>0.615961</td>\n",
       "      <td>0.613275</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>35</td>\n",
       "      <td>0.942178</td>\n",
       "      <td>0.942338</td>\n",
       "      <td>0.941748</td>\n",
       "      <td>0.942088</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>11.766798</td>\n",
       "      <td>115.858841</td>\n",
       "      <td>14.314208</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.614509</td>\n",
       "      <td>0.609619</td>\n",
       "      <td>0.609447</td>\n",
       "      <td>0.611192</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>36</td>\n",
       "      <td>0.914038</td>\n",
       "      <td>0.912263</td>\n",
       "      <td>0.914190</td>\n",
       "      <td>0.913497</td>\n",
       "      <td>0.000875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9.591068</td>\n",
       "      <td>109.658529</td>\n",
       "      <td>8.078924</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 50, 'clf...</td>\n",
       "      <td>0.609279</td>\n",
       "      <td>0.612622</td>\n",
       "      <td>0.610566</td>\n",
       "      <td>0.610822</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>37</td>\n",
       "      <td>0.913514</td>\n",
       "      <td>0.912538</td>\n",
       "      <td>0.913594</td>\n",
       "      <td>0.913216</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>112.041962</td>\n",
       "      <td>128.420215</td>\n",
       "      <td>7.580912</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.613967</td>\n",
       "      <td>0.609793</td>\n",
       "      <td>0.608177</td>\n",
       "      <td>0.610645</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>38</td>\n",
       "      <td>0.995738</td>\n",
       "      <td>0.995867</td>\n",
       "      <td>0.996383</td>\n",
       "      <td>0.995996</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101.727630</td>\n",
       "      <td>96.618731</td>\n",
       "      <td>6.744637</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.611265</td>\n",
       "      <td>0.607456</td>\n",
       "      <td>0.611343</td>\n",
       "      <td>0.610021</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>39</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.996157</td>\n",
       "      <td>0.995675</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27.527287</td>\n",
       "      <td>117.186707</td>\n",
       "      <td>1.264324</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.611866</td>\n",
       "      <td>0.606059</td>\n",
       "      <td>0.610167</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>40</td>\n",
       "      <td>0.995484</td>\n",
       "      <td>0.995783</td>\n",
       "      <td>0.996275</td>\n",
       "      <td>0.995847</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.469590</td>\n",
       "      <td>93.932984</td>\n",
       "      <td>5.350106</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.602741</td>\n",
       "      <td>0.596642</td>\n",
       "      <td>0.604632</td>\n",
       "      <td>0.601338</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>41</td>\n",
       "      <td>0.957851</td>\n",
       "      <td>0.958091</td>\n",
       "      <td>0.958249</td>\n",
       "      <td>0.958064</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.004210</td>\n",
       "      <td>241.551924</td>\n",
       "      <td>5.159407</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.598158</td>\n",
       "      <td>0.602689</td>\n",
       "      <td>0.601540</td>\n",
       "      <td>0.600796</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>42</td>\n",
       "      <td>0.956663</td>\n",
       "      <td>0.957819</td>\n",
       "      <td>0.958326</td>\n",
       "      <td>0.957603</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.188845</td>\n",
       "      <td>97.615562</td>\n",
       "      <td>5.316905</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.604491</td>\n",
       "      <td>0.597560</td>\n",
       "      <td>0.600296</td>\n",
       "      <td>0.600783</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>43</td>\n",
       "      <td>0.958805</td>\n",
       "      <td>0.958103</td>\n",
       "      <td>0.958241</td>\n",
       "      <td>0.958383</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.693957</td>\n",
       "      <td>193.899383</td>\n",
       "      <td>4.024056</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.607912</td>\n",
       "      <td>0.594663</td>\n",
       "      <td>0.598761</td>\n",
       "      <td>0.600445</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>44</td>\n",
       "      <td>0.958778</td>\n",
       "      <td>0.957959</td>\n",
       "      <td>0.957695</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>0.000461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.265320</td>\n",
       "      <td>87.179277</td>\n",
       "      <td>4.327381</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.582009</td>\n",
       "      <td>0.573046</td>\n",
       "      <td>0.575774</td>\n",
       "      <td>0.576943</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>45</td>\n",
       "      <td>0.951929</td>\n",
       "      <td>0.950913</td>\n",
       "      <td>0.952477</td>\n",
       "      <td>0.951773</td>\n",
       "      <td>0.000648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.521872</td>\n",
       "      <td>89.903902</td>\n",
       "      <td>11.521764</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.579999</td>\n",
       "      <td>0.571754</td>\n",
       "      <td>0.575432</td>\n",
       "      <td>0.575728</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>46</td>\n",
       "      <td>0.952382</td>\n",
       "      <td>0.952405</td>\n",
       "      <td>0.951710</td>\n",
       "      <td>0.952166</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.269433</td>\n",
       "      <td>106.797820</td>\n",
       "      <td>4.039186</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.577299</td>\n",
       "      <td>0.571376</td>\n",
       "      <td>0.577286</td>\n",
       "      <td>0.575320</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>47</td>\n",
       "      <td>0.950639</td>\n",
       "      <td>0.951819</td>\n",
       "      <td>0.952493</td>\n",
       "      <td>0.951650</td>\n",
       "      <td>0.000766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.406338</td>\n",
       "      <td>100.342752</td>\n",
       "      <td>6.141212</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.575393</td>\n",
       "      <td>0.574084</td>\n",
       "      <td>0.571982</td>\n",
       "      <td>0.573820</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>48</td>\n",
       "      <td>0.951921</td>\n",
       "      <td>0.950555</td>\n",
       "      <td>0.953043</td>\n",
       "      <td>0.951840</td>\n",
       "      <td>0.001017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    std_fit_time  mean_score_time  std_score_time  \\\n",
       "24     13.790186       132.170944        9.292411   \n",
       "29    130.070811       140.338393       29.341547   \n",
       "28     25.810716       173.954488       10.838890   \n",
       "25      8.702223       114.033495        5.106103   \n",
       "45     59.576437       157.021001       20.917853   \n",
       "41     31.162243       113.612712        2.081775   \n",
       "40      6.189027       117.861618        2.680167   \n",
       "44      7.213611       197.770372       10.708740   \n",
       "13      2.194074       104.414408        4.075895   \n",
       "9       7.382524       239.590553       19.331161   \n",
       "16      2.392148       101.094927        5.576110   \n",
       "8      35.688345       143.502429       31.635779   \n",
       "20     29.643903       148.753648       16.455862   \n",
       "12     18.231480        94.932876        3.066692   \n",
       "17     17.976929       118.644085        7.356616   \n",
       "21     20.522554       125.452465        5.259132   \n",
       "26     11.847645        95.731016        4.661868   \n",
       "32     12.633655        95.248912        4.973207   \n",
       "36      1.686717       154.615375       37.057258   \n",
       "37     10.278171       136.298787       41.011605   \n",
       "27    243.836172       112.245066       37.323402   \n",
       "31      5.496860       121.330342       16.520930   \n",
       "30     10.555890       107.901394        5.918489   \n",
       "42      6.474830       176.256373        9.897513   \n",
       "43     25.587177       158.948393        5.960802   \n",
       "47     83.237135       136.415379        6.667605   \n",
       "33     21.480496        98.040819        6.773904   \n",
       "46     11.489862       135.875515        6.563294   \n",
       "23      6.359034       115.031386        1.574578   \n",
       "39      9.855070       100.816350        6.718141   \n",
       "34      9.150624       120.634084       11.757095   \n",
       "15     16.842788       145.322078        2.789279   \n",
       "18     46.185659       111.222490        7.334794   \n",
       "22     18.172808       124.182717        7.795156   \n",
       "19     44.642881       174.993811       24.013595   \n",
       "35     11.766798       115.858841       14.314208   \n",
       "38      9.591068       109.658529        8.078924   \n",
       "14    112.041962       128.420215        7.580912   \n",
       "10    101.727630        96.618731        6.744637   \n",
       "11     27.527287       117.186707        1.264324   \n",
       "4      12.469590        93.932984        5.350106   \n",
       "1       6.004210       241.551924        5.159407   \n",
       "5       6.188845        97.615562        5.316905   \n",
       "0       4.693957       193.899383        4.024056   \n",
       "6      18.265320        87.179277        4.327381   \n",
       "2      12.521872        89.903902       11.521764   \n",
       "7       9.269433       106.797820        4.039186   \n",
       "3       2.406338       100.342752        6.141212   \n",
       "\n",
       "   param_clf__estimator__min_samples_split param_clf__estimator__n_estimators  \\\n",
       "24                                      10                                 50   \n",
       "29                                      10                                 50   \n",
       "28                                      10                                 50   \n",
       "25                                      10                                 50   \n",
       "45                                      50                                 50   \n",
       "41                                      50                                 50   \n",
       "40                                      50                                 50   \n",
       "44                                      50                                 50   \n",
       "13                                       2                                 50   \n",
       "9                                        2                                 50   \n",
       "16                                      10                                 10   \n",
       "8                                        2                                 50   \n",
       "20                                      10                                 10   \n",
       "12                                       2                                 50   \n",
       "17                                      10                                 10   \n",
       "21                                      10                                 10   \n",
       "26                                      10                                 50   \n",
       "32                                      50                                 10   \n",
       "36                                      50                                 10   \n",
       "37                                      50                                 10   \n",
       "27                                      10                                 50   \n",
       "31                                      10                                 50   \n",
       "30                                      10                                 50   \n",
       "42                                      50                                 50   \n",
       "43                                      50                                 50   \n",
       "47                                      50                                 50   \n",
       "33                                      50                                 10   \n",
       "46                                      50                                 50   \n",
       "23                                      10                                 10   \n",
       "39                                      50                                 10   \n",
       "34                                      50                                 10   \n",
       "15                                       2                                 50   \n",
       "18                                      10                                 10   \n",
       "22                                      10                                 10   \n",
       "19                                      10                                 10   \n",
       "35                                      50                                 10   \n",
       "38                                      50                                 10   \n",
       "14                                       2                                 50   \n",
       "10                                       2                                 50   \n",
       "11                                       2                                 50   \n",
       "4                                        2                                 10   \n",
       "1                                        2                                 10   \n",
       "5                                        2                                 10   \n",
       "0                                        2                                 10   \n",
       "6                                        2                                 10   \n",
       "2                                        2                                 10   \n",
       "7                                        2                                 10   \n",
       "3                                        2                                 10   \n",
       "\n",
       "   param_count__max_df param_count__ngram_range param_tfidf__smooth_idf  \\\n",
       "24                0.75                   (1, 1)                    True   \n",
       "29                   1                   (1, 1)                   False   \n",
       "28                   1                   (1, 1)                    True   \n",
       "25                0.75                   (1, 1)                   False   \n",
       "45                   1                   (1, 1)                   False   \n",
       "41                0.75                   (1, 1)                   False   \n",
       "40                0.75                   (1, 1)                    True   \n",
       "44                   1                   (1, 1)                    True   \n",
       "13                   1                   (1, 1)                   False   \n",
       "9                 0.75                   (1, 1)                   False   \n",
       "16                0.75                   (1, 1)                    True   \n",
       "8                 0.75                   (1, 1)                    True   \n",
       "20                   1                   (1, 1)                    True   \n",
       "12                   1                   (1, 1)                    True   \n",
       "17                0.75                   (1, 1)                   False   \n",
       "21                   1                   (1, 1)                   False   \n",
       "26                0.75                   (1, 2)                    True   \n",
       "32                0.75                   (1, 1)                    True   \n",
       "36                   1                   (1, 1)                    True   \n",
       "37                   1                   (1, 1)                   False   \n",
       "27                0.75                   (1, 2)                   False   \n",
       "31                   1                   (1, 2)                   False   \n",
       "30                   1                   (1, 2)                    True   \n",
       "42                0.75                   (1, 2)                    True   \n",
       "43                0.75                   (1, 2)                   False   \n",
       "47                   1                   (1, 2)                   False   \n",
       "33                0.75                   (1, 1)                   False   \n",
       "46                   1                   (1, 2)                    True   \n",
       "23                   1                   (1, 2)                   False   \n",
       "39                   1                   (1, 2)                   False   \n",
       "34                0.75                   (1, 2)                    True   \n",
       "15                   1                   (1, 2)                   False   \n",
       "18                0.75                   (1, 2)                    True   \n",
       "22                   1                   (1, 2)                    True   \n",
       "19                0.75                   (1, 2)                   False   \n",
       "35                0.75                   (1, 2)                   False   \n",
       "38                   1                   (1, 2)                    True   \n",
       "14                   1                   (1, 2)                    True   \n",
       "10                0.75                   (1, 2)                    True   \n",
       "11                0.75                   (1, 2)                   False   \n",
       "4                    1                   (1, 1)                    True   \n",
       "1                 0.75                   (1, 1)                   False   \n",
       "5                    1                   (1, 1)                   False   \n",
       "0                 0.75                   (1, 1)                    True   \n",
       "6                    1                   (1, 2)                    True   \n",
       "2                 0.75                   (1, 2)                    True   \n",
       "7                    1                   (1, 2)                   False   \n",
       "3                 0.75                   (1, 2)                   False   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "24  {'clf__estimator__min_samples_split': 10, 'clf...           0.646104   \n",
       "29  {'clf__estimator__min_samples_split': 10, 'clf...           0.645896   \n",
       "28  {'clf__estimator__min_samples_split': 10, 'clf...           0.642513   \n",
       "25  {'clf__estimator__min_samples_split': 10, 'clf...           0.644768   \n",
       "45  {'clf__estimator__min_samples_split': 50, 'clf...           0.646768   \n",
       "41  {'clf__estimator__min_samples_split': 50, 'clf...           0.643180   \n",
       "40  {'clf__estimator__min_samples_split': 50, 'clf...           0.643297   \n",
       "44  {'clf__estimator__min_samples_split': 50, 'clf...           0.640349   \n",
       "13  {'clf__estimator__min_samples_split': 2, 'clf_...           0.635859   \n",
       "9   {'clf__estimator__min_samples_split': 2, 'clf_...           0.638198   \n",
       "16  {'clf__estimator__min_samples_split': 10, 'clf...           0.638495   \n",
       "8   {'clf__estimator__min_samples_split': 2, 'clf_...           0.638381   \n",
       "20  {'clf__estimator__min_samples_split': 10, 'clf...           0.632239   \n",
       "12  {'clf__estimator__min_samples_split': 2, 'clf_...           0.632726   \n",
       "17  {'clf__estimator__min_samples_split': 10, 'clf...           0.637248   \n",
       "21  {'clf__estimator__min_samples_split': 10, 'clf...           0.635059   \n",
       "26  {'clf__estimator__min_samples_split': 10, 'clf...           0.632163   \n",
       "32  {'clf__estimator__min_samples_split': 50, 'clf...           0.636286   \n",
       "36  {'clf__estimator__min_samples_split': 50, 'clf...           0.630874   \n",
       "37  {'clf__estimator__min_samples_split': 50, 'clf...           0.630736   \n",
       "27  {'clf__estimator__min_samples_split': 10, 'clf...           0.630307   \n",
       "31  {'clf__estimator__min_samples_split': 10, 'clf...           0.627853   \n",
       "30  {'clf__estimator__min_samples_split': 10, 'clf...           0.629049   \n",
       "42  {'clf__estimator__min_samples_split': 50, 'clf...           0.630896   \n",
       "43  {'clf__estimator__min_samples_split': 50, 'clf...           0.627693   \n",
       "47  {'clf__estimator__min_samples_split': 50, 'clf...           0.628462   \n",
       "33  {'clf__estimator__min_samples_split': 50, 'clf...           0.628096   \n",
       "46  {'clf__estimator__min_samples_split': 50, 'clf...           0.625823   \n",
       "23  {'clf__estimator__min_samples_split': 10, 'clf...           0.621524   \n",
       "39  {'clf__estimator__min_samples_split': 50, 'clf...           0.618984   \n",
       "34  {'clf__estimator__min_samples_split': 50, 'clf...           0.618960   \n",
       "15  {'clf__estimator__min_samples_split': 2, 'clf_...           0.620537   \n",
       "18  {'clf__estimator__min_samples_split': 10, 'clf...           0.621379   \n",
       "22  {'clf__estimator__min_samples_split': 10, 'clf...           0.611466   \n",
       "19  {'clf__estimator__min_samples_split': 10, 'clf...           0.617511   \n",
       "35  {'clf__estimator__min_samples_split': 50, 'clf...           0.614509   \n",
       "38  {'clf__estimator__min_samples_split': 50, 'clf...           0.609279   \n",
       "14  {'clf__estimator__min_samples_split': 2, 'clf_...           0.613967   \n",
       "10  {'clf__estimator__min_samples_split': 2, 'clf_...           0.611265   \n",
       "11  {'clf__estimator__min_samples_split': 2, 'clf_...           0.611866   \n",
       "4   {'clf__estimator__min_samples_split': 2, 'clf_...           0.602741   \n",
       "1   {'clf__estimator__min_samples_split': 2, 'clf_...           0.598158   \n",
       "5   {'clf__estimator__min_samples_split': 2, 'clf_...           0.604491   \n",
       "0   {'clf__estimator__min_samples_split': 2, 'clf_...           0.607912   \n",
       "6   {'clf__estimator__min_samples_split': 2, 'clf_...           0.582009   \n",
       "2   {'clf__estimator__min_samples_split': 2, 'clf_...           0.579999   \n",
       "7   {'clf__estimator__min_samples_split': 2, 'clf_...           0.577299   \n",
       "3   {'clf__estimator__min_samples_split': 2, 'clf_...           0.575393   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "24           0.647428           0.643834         0.645789        0.001484   \n",
       "29           0.643297           0.644738         0.644644        0.001063   \n",
       "28           0.644622           0.645628         0.644255        0.001298   \n",
       "25           0.644787           0.642521         0.644025        0.001064   \n",
       "45           0.637500           0.641883         0.642050        0.003785   \n",
       "41           0.640166           0.641122         0.641489        0.001258   \n",
       "40           0.639647           0.641343         0.641429        0.001491   \n",
       "44           0.640589           0.640200         0.640379        0.000160   \n",
       "13           0.634178           0.635888         0.635308        0.000800   \n",
       "9            0.633463           0.633895         0.635185        0.002137   \n",
       "16           0.635714           0.630324         0.634845        0.003392   \n",
       "8            0.635354           0.630446         0.634727        0.003270   \n",
       "20           0.635894           0.631500         0.633211        0.001921   \n",
       "12           0.630385           0.634395         0.632502        0.001644   \n",
       "17           0.630135           0.629478         0.632287        0.003518   \n",
       "21           0.628885           0.632209         0.632051        0.002523   \n",
       "26           0.627110           0.628243         0.629172        0.002165   \n",
       "32           0.620743           0.630389         0.629139        0.006406   \n",
       "36           0.627840           0.628411         0.629041        0.001316   \n",
       "37           0.626188           0.628994         0.628639        0.001874   \n",
       "27           0.627702           0.627015         0.628341        0.001418   \n",
       "31           0.625522           0.630695         0.628023        0.002116   \n",
       "30           0.625330           0.629054         0.627811        0.001754   \n",
       "42           0.625096           0.625681         0.627224        0.002607   \n",
       "43           0.625834           0.626459         0.626662        0.000773   \n",
       "47           0.621072           0.630242         0.626592        0.003970   \n",
       "33           0.631468           0.619927         0.626497        0.004845   \n",
       "46           0.626987           0.626056         0.626289        0.000503   \n",
       "23           0.616814           0.615634         0.617991        0.002544   \n",
       "39           0.615040           0.614089         0.616038        0.002119   \n",
       "34           0.613228           0.614733         0.615640        0.002426   \n",
       "15           0.610478           0.614214         0.615076        0.004151   \n",
       "18           0.606895           0.614145         0.614140        0.005913   \n",
       "22           0.616822           0.614017         0.614102        0.002188   \n",
       "19           0.606352           0.615961         0.613275        0.004936   \n",
       "35           0.609619           0.609447         0.611192        0.002347   \n",
       "38           0.612622           0.610566         0.610822        0.001377   \n",
       "14           0.609793           0.608177         0.610645        0.002439   \n",
       "10           0.607456           0.611343         0.610021        0.001814   \n",
       "11           0.606059           0.610167         0.609364        0.002438   \n",
       "4            0.596642           0.604632         0.601338        0.003409   \n",
       "1            0.602689           0.601540         0.600796        0.001923   \n",
       "5            0.597560           0.600296         0.600783        0.002851   \n",
       "0            0.594663           0.598761         0.600445        0.005539   \n",
       "6            0.573046           0.575774         0.576943        0.003752   \n",
       "2            0.571754           0.575432         0.575728        0.003373   \n",
       "7            0.571376           0.577286         0.575320        0.002789   \n",
       "3            0.574084           0.571982         0.573820        0.001405   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "24                1            0.946455            0.945730   \n",
       "29                2            0.945473            0.946781   \n",
       "28                3            0.946024            0.945802   \n",
       "25                4            0.946370            0.946305   \n",
       "45                5            0.882716            0.881446   \n",
       "41                6            0.882125            0.881156   \n",
       "40                7            0.881258            0.880984   \n",
       "44                8            0.882277            0.881384   \n",
       "13                9            0.996328            0.996472   \n",
       "9                10            0.996159            0.996726   \n",
       "16               11            0.917717            0.917500   \n",
       "8                12            0.996268            0.996641   \n",
       "20               13            0.918219            0.917419   \n",
       "12               14            0.996232            0.996508   \n",
       "17               15            0.918478            0.917943   \n",
       "21               16            0.920448            0.917567   \n",
       "26               17            0.983988            0.983544   \n",
       "32               18            0.861440            0.856761   \n",
       "36               19            0.861287            0.860480   \n",
       "37               20            0.861648            0.859235   \n",
       "27               21            0.983819            0.983864   \n",
       "31               22            0.983645            0.983133   \n",
       "30               23            0.983956            0.984448   \n",
       "42               24            0.958362            0.959242   \n",
       "43               25            0.958476            0.958593   \n",
       "47               26            0.959467            0.959639   \n",
       "33               27            0.860684            0.859526   \n",
       "46               28            0.960199            0.959668   \n",
       "23               29            0.940395            0.940469   \n",
       "39               30            0.914520            0.911611   \n",
       "34               31            0.915178            0.913201   \n",
       "15               32            0.995592            0.995976   \n",
       "18               33            0.941143            0.941952   \n",
       "22               34            0.942164            0.942414   \n",
       "19               35            0.942178            0.942338   \n",
       "35               36            0.914038            0.912263   \n",
       "38               37            0.913514            0.912538   \n",
       "14               38            0.995738            0.995867   \n",
       "10               39            0.995833            0.996157   \n",
       "11               40            0.995484            0.995783   \n",
       "4                41            0.957851            0.958091   \n",
       "1                42            0.956663            0.957819   \n",
       "5                43            0.958805            0.958103   \n",
       "0                44            0.958778            0.957959   \n",
       "6                45            0.951929            0.950913   \n",
       "2                46            0.952382            0.952405   \n",
       "7                47            0.950639            0.951819   \n",
       "3                48            0.951921            0.950555   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "24            0.946411          0.946199         0.000332  \n",
       "29            0.947829          0.946694         0.000964  \n",
       "28            0.947368          0.946398         0.000692  \n",
       "25            0.948117          0.946931         0.000839  \n",
       "45            0.882753          0.882305         0.000608  \n",
       "41            0.879875          0.881052         0.000921  \n",
       "40            0.881090          0.881111         0.000113  \n",
       "44            0.881425          0.881695         0.000412  \n",
       "13            0.996516          0.996439         0.000080  \n",
       "9             0.996563          0.996483         0.000238  \n",
       "16            0.916965          0.917394         0.000316  \n",
       "8             0.996659          0.996523         0.000180  \n",
       "20            0.919492          0.918377         0.000854  \n",
       "12            0.996898          0.996546         0.000273  \n",
       "17            0.920436          0.918952         0.001072  \n",
       "21            0.917750          0.918588         0.001317  \n",
       "26            0.983948          0.983826         0.000201  \n",
       "32            0.861151          0.859784         0.002141  \n",
       "36            0.861266          0.861011         0.000376  \n",
       "37            0.861125          0.860669         0.001036  \n",
       "27            0.984385          0.984023         0.000257  \n",
       "31            0.984522          0.983767         0.000574  \n",
       "30            0.984879          0.984428         0.000377  \n",
       "42            0.959646          0.959083         0.000536  \n",
       "43            0.959416          0.958828         0.000419  \n",
       "47            0.958888          0.959332         0.000321  \n",
       "33            0.861376          0.860529         0.000764  \n",
       "46            0.959691          0.959853         0.000245  \n",
       "23            0.942103          0.940989         0.000788  \n",
       "39            0.913086          0.913072         0.001187  \n",
       "34            0.914271          0.914217         0.000808  \n",
       "15            0.995904          0.995824         0.000167  \n",
       "18            0.942418          0.941837         0.000527  \n",
       "22            0.943222          0.942600         0.000452  \n",
       "19            0.941748          0.942088         0.000249  \n",
       "35            0.914190          0.913497         0.000875  \n",
       "38            0.913594          0.913216         0.000480  \n",
       "14            0.996383          0.995996         0.000279  \n",
       "10            0.995675          0.995888         0.000200  \n",
       "11            0.996275          0.995847         0.000326  \n",
       "4             0.958249          0.958064         0.000164  \n",
       "1             0.958326          0.957603         0.000696  \n",
       "5             0.958241          0.958383         0.000304  \n",
       "0             0.957695          0.958144         0.000461  \n",
       "6             0.952477          0.951773         0.000648  \n",
       "2             0.951710          0.952166         0.000322  \n",
       "7             0.952493          0.951650         0.000766  \n",
       "3             0.953043          0.951840         0.001017  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.cv_results_).sort_values(by=['rank_test_score']).iloc[:50,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuned model\n",
    "best_model = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.653718058298211"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_scorer(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.41      0.53      1586\n",
      "           1       0.84      0.95      0.89      4959\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      6545\n",
      "   macro avg       0.79      0.68      0.71      6545\n",
      "weighted avg       0.81      0.82      0.80      6545\n",
      "\n",
      "request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      5442\n",
      "           1       0.83      0.50      0.62      1103\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      6545\n",
      "   macro avg       0.87      0.74      0.78      6545\n",
      "weighted avg       0.89      0.90      0.89      6545\n",
      "\n",
      "offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6515\n",
      "           1       0.00      0.00      0.00        30\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6545\n",
      "   macro avg       0.50      0.50      0.50      6545\n",
      "weighted avg       0.99      1.00      0.99      6545\n",
      "\n",
      "aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      3908\n",
      "           1       0.75      0.72      0.73      2637\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      6545\n",
      "   macro avg       0.78      0.78      0.78      6545\n",
      "weighted avg       0.79      0.79      0.79      6545\n",
      "\n",
      "medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      6055\n",
      "           1       0.66      0.09      0.15       490\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      6545\n",
      "   macro avg       0.80      0.54      0.56      6545\n",
      "weighted avg       0.91      0.93      0.90      6545\n",
      "\n",
      "medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6252\n",
      "           1       0.77      0.11      0.20       293\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      6545\n",
      "   macro avg       0.86      0.56      0.59      6545\n",
      "weighted avg       0.95      0.96      0.94      6545\n",
      "\n",
      "search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6361\n",
      "           1       0.71      0.03      0.05       184\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      6545\n",
      "   macro avg       0.84      0.51      0.52      6545\n",
      "weighted avg       0.97      0.97      0.96      6545\n",
      "\n",
      "security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6418\n",
      "           1       0.50      0.01      0.02       127\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      6545\n",
      "   macro avg       0.74      0.50      0.50      6545\n",
      "weighted avg       0.97      0.98      0.97      6545\n",
      "\n",
      "military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6343\n",
      "           1       0.82      0.09      0.16       202\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      6545\n",
      "   macro avg       0.89      0.54      0.57      6545\n",
      "weighted avg       0.97      0.97      0.96      6545\n",
      "\n",
      "water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6137\n",
      "           1       0.85      0.39      0.54       408\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      6545\n",
      "   macro avg       0.90      0.69      0.76      6545\n",
      "weighted avg       0.95      0.96      0.95      6545\n",
      "\n",
      "food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5820\n",
      "           1       0.86      0.62      0.72       725\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      6545\n",
      "   macro avg       0.90      0.80      0.84      6545\n",
      "weighted avg       0.94      0.95      0.94      6545\n",
      "\n",
      "shelter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaplu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      5994\n",
      "           1       0.84      0.36      0.50       551\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      6545\n",
      "   macro avg       0.89      0.68      0.73      6545\n",
      "weighted avg       0.94      0.94      0.93      6545\n",
      "\n",
      "clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6464\n",
      "           1       0.69      0.22      0.34        81\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.84      0.61      0.67      6545\n",
      "weighted avg       0.99      0.99      0.99      6545\n",
      "\n",
      "money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6400\n",
      "           1       1.00      0.02      0.04       145\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      6545\n",
      "   macro avg       0.99      0.51      0.51      6545\n",
      "weighted avg       0.98      0.98      0.97      6545\n",
      "\n",
      "missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6472\n",
      "           1       0.00      0.00      0.00        73\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.49      0.50      0.50      6545\n",
      "weighted avg       0.98      0.99      0.98      6545\n",
      "\n",
      "refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6331\n",
      "           1       0.60      0.01      0.03       214\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      6545\n",
      "   macro avg       0.78      0.51      0.51      6545\n",
      "weighted avg       0.96      0.97      0.95      6545\n",
      "\n",
      "death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6242\n",
      "           1       0.83      0.18      0.29       303\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      6545\n",
      "   macro avg       0.90      0.59      0.64      6545\n",
      "weighted avg       0.96      0.96      0.95      6545\n",
      "\n",
      "other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5701\n",
      "           1       0.66      0.02      0.05       844\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      6545\n",
      "   macro avg       0.76      0.51      0.49      6545\n",
      "weighted avg       0.85      0.87      0.82      6545\n",
      "\n",
      "infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      6119\n",
      "           1       0.25      0.00      0.00       426\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      6545\n",
      "   macro avg       0.59      0.50      0.49      6545\n",
      "weighted avg       0.89      0.93      0.90      6545\n",
      "\n",
      "transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6269\n",
      "           1       0.80      0.09      0.16       276\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      6545\n",
      "   macro avg       0.88      0.54      0.57      6545\n",
      "weighted avg       0.95      0.96      0.95      6545\n",
      "\n",
      "buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6235\n",
      "           1       0.86      0.10      0.18       310\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      6545\n",
      "   macro avg       0.91      0.55      0.58      6545\n",
      "weighted avg       0.95      0.96      0.94      6545\n",
      "\n",
      "electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6407\n",
      "           1       0.67      0.04      0.08       138\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      6545\n",
      "   macro avg       0.82      0.52      0.54      6545\n",
      "weighted avg       0.97      0.98      0.97      6545\n",
      "\n",
      "tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6493\n",
      "           1       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.50      0.50      0.50      6545\n",
      "weighted avg       0.98      0.99      0.99      6545\n",
      "\n",
      "hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6484\n",
      "           1       0.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.50      0.50      0.50      6545\n",
      "weighted avg       0.98      0.99      0.99      6545\n",
      "\n",
      "shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6513\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6545\n",
      "   macro avg       0.50      0.50      0.50      6545\n",
      "weighted avg       0.99      1.00      0.99      6545\n",
      "\n",
      "aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6482\n",
      "           1       0.00      0.00      0.00        63\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.50      0.50      0.50      6545\n",
      "weighted avg       0.98      0.99      0.99      6545\n",
      "\n",
      "other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6243\n",
      "           1       0.20      0.00      0.01       302\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      6545\n",
      "   macro avg       0.58      0.50      0.49      6545\n",
      "weighted avg       0.92      0.95      0.93      6545\n",
      "\n",
      "weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      4782\n",
      "           1       0.84      0.72      0.77      1763\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      6545\n",
      "   macro avg       0.87      0.83      0.85      6545\n",
      "weighted avg       0.88      0.89      0.88      6545\n",
      "\n",
      "floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6018\n",
      "           1       0.89      0.46      0.60       527\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      6545\n",
      "   macro avg       0.92      0.73      0.79      6545\n",
      "weighted avg       0.95      0.95      0.94      6545\n",
      "\n",
      "storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      5963\n",
      "           1       0.73      0.61      0.66       582\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      6545\n",
      "   macro avg       0.85      0.79      0.82      6545\n",
      "weighted avg       0.94      0.95      0.94      6545\n",
      "\n",
      "fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6483\n",
      "           1       0.33      0.02      0.03        62\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6545\n",
      "   macro avg       0.66      0.51      0.51      6545\n",
      "weighted avg       0.98      0.99      0.99      6545\n",
      "\n",
      "earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5949\n",
      "           1       0.89      0.79      0.84       596\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      6545\n",
      "   macro avg       0.93      0.89      0.91      6545\n",
      "weighted avg       0.97      0.97      0.97      6545\n",
      "\n",
      "cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6420\n",
      "           1       0.73      0.06      0.12       125\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      6545\n",
      "   macro avg       0.85      0.53      0.55      6545\n",
      "weighted avg       0.98      0.98      0.97      6545\n",
      "\n",
      "other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6213\n",
      "           1       0.58      0.03      0.06       332\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      6545\n",
      "   macro avg       0.76      0.52      0.52      6545\n",
      "weighted avg       0.93      0.95      0.93      6545\n",
      "\n",
      "direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      5280\n",
      "           1       0.76      0.38      0.51      1265\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      6545\n",
      "   macro avg       0.81      0.68      0.71      6545\n",
      "weighted avg       0.85      0.86      0.84      6545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_tuned = pd.DataFrame(best_model.predict(X_test), columns = y_test.columns)\n",
    "for col in y_test.columns:\n",
    "    print(col)\n",
    "    print(classification_report(y_test[col],y_pred_tuned[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaplu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.26743351618105116"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred_tuned, y_test, average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.17      0.28      1495\n",
      "          1       0.80      0.98      0.88      5050\n",
      "\n",
      "avg / total       0.79      0.80      0.74      6545\n",
      "\n",
      "request\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94      5490\n",
      "          1       0.82      0.48      0.61      1055\n",
      "\n",
      "avg / total       0.89      0.90      0.89      6545\n",
      "\n",
      "offer\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6507\n",
      "          1       0.00      0.00      0.00        38\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6545\n",
      "\n",
      "aid_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.89      0.80      3828\n",
      "          1       0.78      0.54      0.64      2717\n",
      "\n",
      "avg / total       0.75      0.75      0.74      6545\n",
      "\n",
      "medical_help\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      6019\n",
      "          1       0.64      0.19      0.29       526\n",
      "\n",
      "avg / total       0.91      0.93      0.91      6545\n",
      "\n",
      "medical_products\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98      6216\n",
      "          1       0.67      0.28      0.40       329\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6545\n",
      "\n",
      "search_and_rescue\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      6363\n",
      "          1       0.33      0.19      0.24       182\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6545\n",
      "\n",
      "security\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      6432\n",
      "          1       0.07      0.05      0.06       113\n",
      "\n",
      "avg / total       0.97      0.97      0.97      6545\n",
      "\n",
      "military\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      6323\n",
      "          1       0.64      0.30      0.41       222\n",
      "\n",
      "avg / total       0.96      0.97      0.97      6545\n",
      "\n",
      "water\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      6154\n",
      "          1       0.73      0.67      0.70       391\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6545\n",
      "\n",
      "food\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97      5805\n",
      "          1       0.79      0.78      0.79       740\n",
      "\n",
      "avg / total       0.95      0.95      0.95      6545\n",
      "\n",
      "shelter\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97      5978\n",
      "          1       0.79      0.55      0.65       567\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6545\n",
      "\n",
      "clothing\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      6444\n",
      "          1       0.59      0.59      0.59       101\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6545\n",
      "\n",
      "money\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      6402\n",
      "          1       0.43      0.20      0.27       143\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6545\n",
      "\n",
      "missing_people\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      6462\n",
      "          1       0.16      0.13      0.14        83\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6545\n",
      "\n",
      "refugees\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      6324\n",
      "          1       0.43      0.23      0.30       221\n",
      "\n",
      "avg / total       0.95      0.96      0.96      6545\n",
      "\n",
      "death\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      6225\n",
      "          1       0.68      0.47      0.56       320\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6545\n",
      "\n",
      "other_aid\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93      5690\n",
      "          1       0.63      0.08      0.15       855\n",
      "\n",
      "avg / total       0.85      0.87      0.83      6545\n",
      "\n",
      "infrastructure_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6136\n",
      "          1       0.60      0.04      0.08       409\n",
      "\n",
      "avg / total       0.92      0.94      0.91      6545\n",
      "\n",
      "transport\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      6246\n",
      "          1       0.65      0.25      0.36       299\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6545\n",
      "\n",
      "buildings\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      6219\n",
      "          1       0.72      0.33      0.46       326\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6545\n",
      "\n",
      "electricity\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      6399\n",
      "          1       0.46      0.23      0.30       146\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6545\n",
      "\n",
      "tools\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6501\n",
      "          1       0.10      0.07      0.08        44\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6545\n",
      "\n",
      "hospitals\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      6476\n",
      "          1       0.07      0.04      0.05        69\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6545\n",
      "\n",
      "shops\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6511\n",
      "          1       0.03      0.03      0.03        34\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6545\n",
      "\n",
      "aid_centers\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      6462\n",
      "          1       0.15      0.08      0.11        83\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6545\n",
      "\n",
      "other_infrastructure\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6275\n",
      "          1       0.28      0.03      0.05       270\n",
      "\n",
      "avg / total       0.93      0.96      0.94      6545\n",
      "\n",
      "weather_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92      4738\n",
      "          1       0.87      0.62      0.73      1807\n",
      "\n",
      "avg / total       0.87      0.87      0.86      6545\n",
      "\n",
      "floods\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98      6019\n",
      "          1       0.90      0.54      0.68       526\n",
      "\n",
      "avg / total       0.96      0.96      0.95      6545\n",
      "\n",
      "storm\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97      5959\n",
      "          1       0.77      0.62      0.69       586\n",
      "\n",
      "avg / total       0.95      0.95      0.95      6545\n",
      "\n",
      "fire\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6469\n",
      "          1       0.42      0.29      0.34        76\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6545\n",
      "\n",
      "earthquake\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      5935\n",
      "          1       0.84      0.82      0.83       610\n",
      "\n",
      "avg / total       0.97      0.97      0.97      6545\n",
      "\n",
      "cold\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      6403\n",
      "          1       0.53      0.37      0.43       142\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6545\n",
      "\n",
      "other_weather\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      6194\n",
      "          1       0.51      0.13      0.20       351\n",
      "\n",
      "avg / total       0.93      0.95      0.93      6545\n",
      "\n",
      "direct_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92      5313\n",
      "          1       0.76      0.34      0.47      1232\n",
      "\n",
      "avg / total       0.85      0.86      0.83      6545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Try GradientBoostingClassifier instead of RandomForestClassifier\n",
    "pipeline2 = Pipeline([\n",
    "    ('count', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(GradientBoostingClassifier()))   \n",
    "])\n",
    "\n",
    "pipeline2.fit(X_train,y_train)\n",
    "\n",
    "y_pred2 = pd.DataFrame(pipeline2.predict(X_test), columns = y_test.columns)\n",
    "\n",
    "for col in y_test.columns:\n",
    "    print(col)\n",
    "    print(classification_report(y_test[col],y_pred2[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65440769826346645"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred2, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'classifier.pkl'\n",
    "pickle.dump(best_model, open(filename, 'wb'))\n",
    "\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
